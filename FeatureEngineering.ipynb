{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook loads the data, engineers features then saves the engineered dataset to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create customer demographic dataframe, add the features listed below\n",
    "\n",
    "account_age - time since account was created in days. 'Now' is taken to be the most recent date in the receipt database, 30/3/2015\n",
    "\n",
    "account_age_months - same as above but in months rather than days\n",
    "\n",
    "customer_age - customer's age in years rounded down\n",
    "\n",
    "Additionally:\n",
    "\n",
    "Churn label is also converted from 2 and 1 to 1 and 0 (churn/not churn respectively)\n",
    "\n",
    "Dates are converted to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_customer_df():\n",
    "    \n",
    "    ## latest date in receipt data\n",
    "    latest_date = dt.date(2014,3,30)\n",
    "\n",
    "    ## read customer demographic data and add header\n",
    "    customers_df = pd.read_table(\"customer/000000_0\",\n",
    "                                 header=None,\n",
    "                                 names = ['customer_id','churn_label',\n",
    "                                          'gender','country','date_created',\n",
    "                                          'YOB','premier'])\n",
    "    \n",
    "    ##convert churn label to 0 and 1\n",
    "    customers_df[\"churn_label\"] = customers_df[\"churn_label\"] - 1\n",
    "\n",
    "    ##convert date_created to datetime object\n",
    "    customers_df[\"date_created\"] = pd.to_datetime(customers_df[\"date_created\"])\n",
    "\n",
    "    ##convert year of birth to datetime object\n",
    "    customers_df[\"YOB\"] = pd.to_datetime(customers_df[\"YOB\"],format='%Y')\n",
    "\n",
    "    ##insert account age in days, most recent order in receipts data is 30/3/2014\n",
    "    customers_df[\"account_age\"] = (latest_date - customers_df[\"date_created\"]).dt.days\n",
    "\n",
    "    ##insert account age in months (rounded to nearest month), better for plotting\n",
    "    customers_df[\"account_age_months\"] = np.rint((latest_date - customers_df[\"date_created\"]).dt.days/(365/12))\n",
    "\n",
    "    ##insert customer age in years\n",
    "    customers_df[\"customer_age\"] = np.floor((latest_date - customers_df[\"YOB\"]).dt.days/365)\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read receipt data\n",
    "\n",
    "Convert signal_datetime to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_receipts_data():\n",
    "    \n",
    "    dfs_to_concat = []\n",
    "\n",
    "    for i in range(0,3):                                                            \n",
    "        dfs_to_concat.append(\n",
    "            pd.read_table(\"receipts/00000%d_0\" % i,header=None,names = ['customer_id','product_id',\n",
    "                                                                'source_id','division_id','item_qty',\n",
    "                                                                'signal_datetime','receipt_id','price']))\n",
    "        \n",
    "    receipts_df = pd.concat(dfs_to_concat)\n",
    "        \n",
    "    receipts_df[\"signal_datetime\"] = pd.to_datetime(receipts_df[\"signal_datetime\"])\n",
    "        \n",
    "    return receipts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create order summary dataframe\n",
    "\n",
    "Dataframe contains a summary of each order. In the receipts data there is a row for every unique product in an order. These rows can be aggregated into a summary for each order by grouping them by receipt_id (the unique identifier of the order) and summing over price and number of items to give total order value and number of items bought for a given order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_order_summary_df(receipts_df):\n",
    "\n",
    "    ##group all orders (groupby columns are not aggregated) and sum over item_qty and price\n",
    "    ##to give total noumber of items and total order value\n",
    "    order_sum_df = receipts_df.groupby(\n",
    "        ['receipt_id','signal_datetime','customer_id']).sum().reset_index()\n",
    "\n",
    "    ##drop product_id, source_id, division_id columns as they are now meaningless (we have summed them up)\n",
    "    order_sum_df.drop(['product_id','source_id', 'division_id'], axis = 1, inplace = True)\n",
    "\n",
    "    ##add in date (used late for groupby operations)\n",
    "    order_sum_df[\"date\"] = order_sum_df[\"signal_datetime\"].dt.date\n",
    "    \n",
    "    return order_sum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create customer's orders summary dataframe\n",
    "\n",
    "Dataframe contains a summary of all of a customer's orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_customer_order_summary_df(receipts_df):\n",
    "    \n",
    "    ##group orders by customer id and aggregate by summing\n",
    "    customer_order_sum_df = receipts_df.groupby('customer_id').sum().reset_index()\n",
    "    \n",
    "    #drop meaningless columns (we have summed over them)\n",
    "    customer_order_sum_df.drop(\n",
    "    ['product_id','source_id', 'division_id','receipt_id'], axis = 1, inplace = True)\n",
    "    \n",
    "    customer_order_sum_df.rename(columns={'price' : 'total_spent'}, inplace = True)\n",
    "    \n",
    "    #add rounded price for plotting\n",
    "    customer_order_sum_df[\"rounded_total_spent\"] = np.rint(customer_order_sum_df[\"total_spent\"])\n",
    "    \n",
    "    return customer_order_sum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read returns data and return dataframe\n",
    "\n",
    "Add separate column for each return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_returns_data():\n",
    "    \n",
    "    ##read returns data\n",
    "    returns_df = pd.read_table(\"returns/000000_0\",header=None,names = ['customer_id','product_id',\n",
    "                                                    'source_id','division_id','item_qty',\n",
    "                                                    'signal_datetime','receipt_id', 'return_id',\n",
    "                                                    'return_action','return_reason'])\n",
    "    \n",
    "    ##convert signal timestampe to datetime\n",
    "    returns_df[\"signal_datetime\"] = pd.to_datetime(returns_df[\"signal_datetime\"])\n",
    "    \n",
    "    #add new column for each return action, 1 indicates that, that return action that was taken\n",
    "    return_actions = [\"Refund\",\"Cancel\",\"Replacement\",\"Reject\"]\n",
    "    \n",
    "    for action in return_actions:\n",
    "        returns_df[action] = returns_df[\"return_action\"].apply(lambda x : 1 if x == action else 0)\n",
    "    \n",
    "    return returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create returns summary dataframe\n",
    "\n",
    "Dataframe contains a summary of each return. Just like the receipts data there is a row for every unique product returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_returns_summary_df(returns_df):\n",
    "    \n",
    "    # create a summary dataframe of returns\n",
    "    returns_sum_df = returns_df.groupby(\n",
    "        ['return_id','signal_datetime','customer_id']).sum().reset_index()\n",
    "\n",
    "    #drop columns that are now meaningless (we have summed over them)\n",
    "    returns_sum_df.drop(['receipt_id','product_id','source_id', 'division_id'], axis = 1, inplace = True)\n",
    "    \n",
    "    return returns_sum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create customer's returns summary dataframe\n",
    "\n",
    "Dataframe contains a summary of each return. Just like the receipts data there is a row for every unique product returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_customer_returns_summary_df(returns_df):\n",
    "    \n",
    "    # create a summary of customer's returns dataframe\n",
    "    customer_returns_sum_df = returns_df.groupby('customer_id').sum().reset_index()\n",
    "\n",
    "    #rename sum of items returned as number of returned items\n",
    "    customer_returns_sum_df.rename(columns={'item_qty': 'no_returned_items'}, inplace=True)\n",
    "\n",
    "    #drop columns that are now meaningless\n",
    "    customer_returns_sum_df.drop(\n",
    "        ['receipt_id','return_id','product_id','source_id', 'division_id'], axis = 1, inplace = True)\n",
    "    \n",
    "    return customer_returns_sum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load browsing data\n",
    "\n",
    "Load browsing data, drop information to do with browser (large dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_browsing_data():\n",
    "\n",
    "    dfs_to_concat = []\n",
    "\n",
    "    for i in range(0,18):                                                            \n",
    "        dfs_to_concat.append(\n",
    "            pd.read_table(\"sessionsummary/0000%02d_0\" % i,\n",
    "                          header=None,\n",
    "                          names = ['customer_id','country',\n",
    "                                    'start_time','site','page_views',\n",
    "                                    'non_page_view_events','user_agent',\n",
    "                                    'screen_res','browser_size','product_views',\n",
    "                                    'product_views_dist',\n",
    "                                    'added_to_bag','saved_for_l8r_prod',\n",
    "                                    'saved_for_l8r_cat','purchased_distinct',\n",
    "                                    'purchased_total']))\n",
    "        \n",
    "    browsing_df = pd.concat(dfs_to_concat)\n",
    "\n",
    "    #drop website and browser info\n",
    "    browsing_df.drop([\"site\",\"user_agent\",\"screen_res\",\"browser_size\"],axis = 1,inplace=True)\n",
    "\n",
    "    #convert start time timestamp to datetime object\n",
    "    browsing_df[\"start_time\"] = pd.to_datetime(browsing_df[\"start_time\"])\n",
    "    \n",
    "    return browsing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert time elapsed since the customers last order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_time_elapsed_since_last_order(customers_df,recipts_df):\n",
    "\n",
    "    latest_date = dt.datetime(2014,4,30)\n",
    "\n",
    "    #group orders by customer id then find the max order datetime (latest)\n",
    "    last_order_df = pd.DataFrame(receipts_df.groupby(\"customer_id\")[\"signal_datetime\"].max()).reset_index()\n",
    "\n",
    "    ##rename signal_datetime\n",
    "    last_order_df.rename(columns={'signal_datetime' : 'last_order_datetime'}, inplace=True)\n",
    "\n",
    "    ##calculate elapsed time\n",
    "    last_order_df[\"time_elapsed_since_last\"] = (latest_date - last_order_df[\"last_order_datetime\"]).dt.days\n",
    "        \n",
    "    customers_df = pd.merge(\n",
    "    customers_df,last_order_df[[\"customer_id\",\"time_elapsed_since_last\"]],on=\"customer_id\",how=\"left\")\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the total number of orders a customer has made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_number_of_orders(customers_df,order_sum_df):\n",
    "\n",
    "    #create dataframe of number of orders, groupby customer_id then count number of orders\n",
    "    #(you can count any column as you are just counting the number of rows for a given customer_id)\n",
    "    num_of_orders = pd.DataFrame(order_sum_df.groupby([\"customer_id\"])[\"receipt_id\"].count()).reset_index()\n",
    "\n",
    "    #rename columns\n",
    "    num_of_orders.rename(columns={\"receipt_id\" : \"no_of_orders\"}, inplace = True)\n",
    "\n",
    "    customers_df = pd.merge(customers_df,num_of_orders[[\"customer_id\",\"no_of_orders\"]],on=\"customer_id\",\n",
    "                           how='left')\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_number_of_orders_in_last_n_days(customers_df,order_sum_df,days):\n",
    "    \n",
    "    latest_date = dt.datetime(2014,4,30)\n",
    "    \n",
    "    ##find date n days ago\n",
    "    n_days_ago = latest_date - dt.timedelta(days)\n",
    "    \n",
    "    #find orders in last n_days, groupby customer_id then count number of orders\n",
    "    #(you can count any column as you are just counting the number of rows for a given customer_id)\n",
    "    orders_last_n_days = order_sum_df[order_sum_df.signal_datetime > n_days_ago].groupby(\n",
    "        [\"customer_id\"])[\"receipt_id\"].count().reset_index()\n",
    "    \n",
    "    ##rename column\n",
    "    orders_last_n_days.rename(columns={'receipt_id': 'orders_last_'+str(days)+'_days'}, inplace=True)\n",
    "\n",
    "    ## add to customer df\n",
    "    customers_df = pd.merge(\n",
    "        customers_df,orders_last_n_days[['customer_id','orders_last_'+str(days)+'_days']],on=\"customer_id\",\n",
    "        how='left')\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_amount_spent_in_last_n_days(customers_df,order_sum_df,days):\n",
    "    \n",
    "    latest_date = dt.datetime(2014,4,30)\n",
    "    \n",
    "    ##find date n days ago\n",
    "    n_days_ago = latest_date - dt.timedelta(days)\n",
    "    \n",
    "    #create dataframe of number of orders, groupby customer_id then sum over price to get total spend\n",
    "    spent_last_n_days = order_sum_df[order_sum_df.signal_datetime > n_days_ago].groupby(\n",
    "        [\"customer_id\"])[\"price\"].sum().reset_index()\n",
    "    \n",
    "    spent_last_n_days.rename(columns={'price': 'spent_last_'+str(days)+'_days'}, inplace=True)\n",
    "\n",
    "    customers_df = pd.merge(\n",
    "        customers_df,spent_last_n_days[['customer_id','spent_last_'+str(days)+'_days']],on=\"customer_id\",\n",
    "        how='left')\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_time_elapsed_since_last_browse(customers_df,browsing_df):\n",
    "    \n",
    "    latest_date = dt.datetime(2014,4,30)\n",
    "    \n",
    "    last_browse_df = pd.DataFrame(browsing_df.groupby(\"customer_id\")[\"start_time\"].max()).reset_index()\n",
    "\n",
    "    last_browse_df.rename(columns={'start_time': 'last_browse'}, inplace=True)\n",
    "\n",
    "    last_browse_df[\"days_since_last_browse\"] = (latest_date - last_browse_df[\"last_browse\"]).dt.days\n",
    "    \n",
    "    customers_df = pd.merge(\n",
    "        customers_df,last_browse_df[['customer_id','days_since_last_browse']],on=\"customer_id\", how='left')\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_site_visits_last_n_days(customers_df,browsing_df,days):\n",
    "    \n",
    "    latest_date = dt.datetime(2014,4,30)\n",
    "    \n",
    "    ##find date n days ago\n",
    "    n_days_ago = latest_date - dt.timedelta(days)\n",
    "    \n",
    "    #create dataframe of number of site visits in last n days\n",
    "    visits_last_n_days = browsing_df[browsing_df.start_time > n_days_ago].groupby(\n",
    "        [\"customer_id\"])[\"start_time\"].count().reset_index()\n",
    "    \n",
    "    visits_last_n_days.rename(columns={'start_time': 'visits_last_'+str(days)+'_days'}, inplace=True)\n",
    "\n",
    "    customers_df = pd.merge(\n",
    "        customers_df,visits_last_n_days[['customer_id','visits_last_'+str(days)+'_days']],on=\"customer_id\",\n",
    "        how='left')\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duncan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/home/duncan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/home/duncan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Load the datasets\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "## Load customer data\n",
    "customers_df = create_customer_df()\n",
    "\n",
    "## Load receipts data\n",
    "receipts_df = read_receipts_data()\n",
    "\n",
    "## Create order summary and customer order summary dataframes\n",
    "\n",
    "order_sum_df = create_order_summary_df(receipts_df)\n",
    "\n",
    "customer_order_sum_df = create_customer_order_summary_df(receipts_df)\n",
    "\n",
    "## Load returns data\n",
    "\n",
    "returns_df = read_returns_data()\n",
    "\n",
    "## Create returns summary and customer returns summary dataframes\n",
    "\n",
    "returns_sum_df = create_returns_summary_df(returns_df)\n",
    "\n",
    "customer_returns_sum_df = create_customer_returns_summary_df(returns_df) \n",
    "\n",
    "## Load browsing data\n",
    "\n",
    "browsing_df = read_browsing_data()\n",
    "\n",
    "## Create customer browsing summary dataframe\n",
    "\n",
    "customer_browsing_df = browsing_df.groupby(\"customer_id\").sum().reset_index()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Engineer features and add them to customer_df\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "## First add order, return and browsing summaries\n",
    "\n",
    "customers_df = pd.merge(\n",
    "    customers_df,customer_order_sum_df,on=\"customer_id\",how='left')\n",
    "\n",
    "customers_df = pd.merge(\n",
    "    customers_df,customer_returns_sum_df,on=\"customer_id\",how='left')\n",
    "\n",
    "customers_df = pd.merge(\n",
    "    customers_df,customer_browsing_df,on=\"customer_id\",how='left')\n",
    "\n",
    "## Add bought/return ratio\n",
    "\n",
    "customers_df.rename(columns={\"item_qty\" : \"no_items_bought\"}, inplace = True)\n",
    "\n",
    "customers_df[\"bought_return_ratio\"] = customers_df[\"no_returned_items\"]/customers_df[\"no_items_bought\"]\n",
    "\n",
    "## Add time elapsed since last order\n",
    "\n",
    "customers_df = insert_time_elapsed_since_last_order(customers_df,receipts_df)\n",
    "\n",
    "customers_df = insert_number_of_orders(customers_df,order_sum_df)\n",
    "\n",
    "## Add number of orders in last year, last 6 months, last 3 days and last month\n",
    "\n",
    "time_periods = [365, 182, 92, 31]\n",
    "\n",
    "for days in time_periods:\n",
    "    customers_df = insert_number_of_orders_in_last_n_days(customers_df,order_sum_df, days)\n",
    "\n",
    "## Add amount spent in last year, last 6 months, last 3 days and last month\n",
    "    \n",
    "for days in time_periods:\n",
    "    customers_df = insert_amount_spent_in_last_n_days(customers_df,order_sum_df, days)\n",
    "\n",
    "## Add time elapsed since last browse    \n",
    "    \n",
    "customers_df = insert_time_elapsed_since_last_browse(customers_df,browsing_df)\n",
    "\n",
    "## Insert site visits in last year, last 6 months, last 3 days and last month\n",
    "for days in time_periods:\n",
    "    customers_df = insert_site_visits_last_n_days(customers_df,browsing_df,days)\n",
    "    \n",
    "## Insert total site visits (just use large number of days)\n",
    "\n",
    "customers_df = insert_site_visits_last_n_days(customers_df,browsing_df,10000)\n",
    "\n",
    "customers_df.rename(columns={'visits_last_10000_days' : 'total_site_visits'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customers_df.to_pickle('./customer_df_with_engineered_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470169, 41)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
